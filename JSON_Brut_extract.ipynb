{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulienDbrt/BGS-Invoice/blob/main/JSON_Brut_extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DJc4oMcIi5W"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle-gpu paddleocr\n",
        "!apt-get install -y poppler-utils\n",
        "!wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.0g-2ubuntu4_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.0g-2ubuntu4_amd64.deb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTjeM6Q9jCWD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BJ5bfGNcQTI"
      },
      "outputs": [],
      "source": [
        "!pip install openai mistralai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction simple du fichier JSON en CSV - sans la clé \"Pages\"\n",
        "\n",
        "import glob\n",
        "import json\n",
        "import chardet\n",
        "import csv\n",
        "from json import JSONDecodeError\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/Complet'\n",
        "output_file_path = '/content/json_final_output_json.csv'\n",
        "\n",
        "def extract_data_json(json_file_path):\n",
        "    \"\"\"\n",
        "    Extracts data from a JSON file and returns it in a dictionary format.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(json_file_path, 'rb') as file:\n",
        "            raw_data = file.read()\n",
        "            encoding = chardet.detect(raw_data)['encoding'] or 'utf-8'\n",
        "            json_data = json.loads(raw_data.decode(encoding))\n",
        "    except JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON file {json_file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    data_mapped = {\n",
        "        \"vendorEmail\": json_data.get(\"tiersEmail\", \"\"),\n",
        "        \"uo_2\": json_data.get(\"uo_2\", \"\"),\n",
        "        \"invoiceNumber\": json_data.get(\"numeroPiece\", \"\"),\n",
        "        \"vendorCode\": json_data.get(\"codeTiers\", \"\"),\n",
        "        \"commitmentCode\": json_data.get(\"codeEngagement\", \"\"),\n",
        "        \"title\": json_data.get(\"title\", \"\"),\n",
        "        \"dueDate\": json_data.get(\"dateEcheance\", \"\"),\n",
        "        \"documentType\": json_data.get(\"typeDocument\", \"\"),\n",
        "        \"vendorSiret\": json_data.get(\"tiersSiret\", \"\"),\n",
        "        \"projectCode\": json_data.get(\"codeProjet\", \"\"),\n",
        "        \"ttc\": json_data.get(\"ttc\", \"\"),\n",
        "        \"tiers\": json_data.get(\"tiers\", \"\"),\n",
        "        \"ht\": json_data.get(\"ht\", \"\"),\n",
        "        \"dateDocument\": json_data.get(\"dateDocument\", \"\"),\n",
        "        \"subChapter\": json_data.get(\"sousChapitre\", \"\"),\n",
        "        \"commitment\": json_data.get(\"engagement\", \"\"),\n",
        "        \"project\": json_data.get(\"projet\", \"\"),\n",
        "        \"invoiceType\": json_data.get(\"typeFacture\", \"\")\n",
        "    }\n",
        "\n",
        "    return data_mapped\n",
        "\n",
        "def process_json_files(directory_path, output_file_path):\n",
        "    \"\"\"\n",
        "    Processes all JSON files in the given directory and writes the data into a CSV file.\n",
        "    \"\"\"\n",
        "    json_files = glob.glob(f\"{directory_path}/*.json\")\n",
        "    results = []\n",
        "\n",
        "    for file_path in json_files:\n",
        "        filename = file_path.split('/')[-1]\n",
        "        invoice_data = extract_data_json(file_path)\n",
        "        if invoice_data:\n",
        "            invoice_data['filename'] = filename\n",
        "            results.append(invoice_data)\n",
        "\n",
        "    with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = [\n",
        "            \"filename\", \"vendorEmail\", \"uo_2\", \"invoiceNumber\", \"vendorCode\", \"commitmentCode\", \"title\",\n",
        "            \"dueDate\", \"documentType\", \"vendorSiret\", \"projectCode\", \"ttc\", \"tiers\", \"ht\", \"dateDocument\",\n",
        "            \"subChapter\", \"commitment\", \"project\", \"invoiceType\"\n",
        "        ]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for item in results:\n",
        "            writer.writerow(item)\n",
        "\n",
        "process_json_files(directory_path, output_file_path)\n"
      ],
      "metadata": {
        "id": "9igGLIbM22IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bq8kYB_D97w"
      },
      "source": [
        "# Skipped :\n",
        "64060\n",
        "63257\n",
        "63155\n",
        "63820\n",
        "63155\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misltal AI"
      ],
      "metadata": {
        "id": "PtzjOLl99O6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction de \"Pages\", nettoyage de la données et envoie dans Mistral API\n",
        "\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import glob\n",
        "import json\n",
        "import chardet\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from mistralai.client import MistralClient\n",
        "from pydantic import BaseModel\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "\n",
        "api_key = userdata.get(\"MISTRAL_API_KEY\")\n",
        "client = MistralClient(api_key=api_key)\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/Complet'\n",
        "output_file_path = '/content/json_final_output_mistral.csv'\n",
        "\n",
        "class Result(BaseModel):\n",
        "    vendorEmail: str\n",
        "    uo_2: str\n",
        "    invoiceNumber: str\n",
        "    vendorCode: str\n",
        "    commitmentCode: str\n",
        "    title: str\n",
        "    dueDate: str\n",
        "    documentType: str\n",
        "    vendorSiret: str\n",
        "    projectCode: str\n",
        "    ttc: str\n",
        "    tiers: str\n",
        "    ht: str\n",
        "    dateDocument: str\n",
        "    subChapter: str\n",
        "    commitment: str\n",
        "    project: str\n",
        "    invoiceType: str\n",
        "\n",
        "def estimate_token_count(text):\n",
        "    \"\"\"Estimate the number of tokens based on the text length.\n",
        "    Rough estimation assuming an average token length, including spaces.\"\"\"\n",
        "    return len(text) / 5\n",
        "\n",
        "def extract_data_json(json_file_path):\n",
        "    \"\"\"Extract and process data from a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(json_file_path, 'rb') as file:\n",
        "            raw_data = file.read()\n",
        "            if not raw_data:\n",
        "                print(f\"Warning: The file {json_file_path} is empty.\")\n",
        "                return None\n",
        "            encoding = chardet.detect(raw_data)['encoding'] or 'utf-8'\n",
        "            json_data = json.loads(raw_data.decode(encoding))\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from the file {json_file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    pages_data = json_data.get('pages', [])\n",
        "    sentences = []\n",
        "\n",
        "    for page in pages_data:\n",
        "        if page.get('$type') == 'PageContent':\n",
        "            for text_zone in page.get('Items', []):\n",
        "                if text_zone.get('$type') == 'TextZone':\n",
        "                    for line in text_zone.get('Ln', []):\n",
        "                        for item in line.get('Items', []):\n",
        "                            if item.get('$type') == 'Word':\n",
        "                                sentences.append(item.get('Value', ''))\n",
        "\n",
        "    sentence = ' '.join(sentences)\n",
        "    file_name = os.path.basename(json_file_path)\n",
        "    return {'sentence': sentence, 'file_name': file_name}\n",
        "\n",
        "def process_json_files(directory_path, output_file_path):\n",
        "    json_files = glob.glob(f\"{directory_path}/*.json\")\n",
        "    results = []\n",
        "    print(f\"Processing {len(json_files)} files...\")\n",
        "\n",
        "    for file_path in tqdm(json_files, desc=\"Progress\"):\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "        invoice_data = extract_data_json(file_path)\n",
        "        if invoice_data is None:\n",
        "            continue\n",
        "\n",
        "        sentence = invoice_data.get('sentence', '')\n",
        "        token_count = estimate_token_count(sentence)\n",
        "        if token_count > 32000:\n",
        "            max_length = 32000 * 5\n",
        "            invoice_data['sentence'] = sentence[:max_length]\n",
        "\n",
        "        document_details = invoice_data\n",
        "\n",
        "        token_count = estimate_token_count(document_details)\n",
        "        print(f\"Estimated token count for {file_path}: {token_count}\")\n",
        "\n",
        "        if token_count > 31000:\n",
        "            print(f\"{file_path} skipped due to token limit\")\n",
        "            continue\n",
        "\n",
        "        model = 'mistral-small-latest'\n",
        "\n",
        "        prompt = [\n",
        "            ChatMessage(role=\"system\", content='Create a JSON output with the following keys and their respective keys.  If the key is not present, the field is filled with an empty string or appears as NaN (Not a Number) in the dataset : vendor Email: Represents the email address of the vendor. uo_2: Denotes a specific organizational unit or department within a company, indicated by the key \"uo_2\". \"numeroPiece\": Contains the invoice number. \"codeTiers\": Corresponds to a unique code assigned to the vendor. \"codeEngagement\": Refers to a specific commitment or contract code associated with the invoice. \"title\": The title or name of the document, Title listed on the invoice, which usually describes the service or product sold. \"dueDate\": Indicates the due date of the invoice. \"typeDocument\": Specifies the type of document based on a pre-defined set of categories (09.01 - Factures / 09.04 - Factures développement (avant promesse) / 09.07 - Factures marketing / 09.08 - Factures travaux et prorata / 09.21 - Honoraires juridiques / 09.22 - Honoraires prescripteurs / 09.31 - Situations travaux MOE BPCC / 09.32 - Situations travaux MOE externe. »). \"tiersSiret\": A French SIRET number unique to each French company.  \"codeProjet\": Represents a unique code for the project associated with the invoice. \"ttc\": The total amount to be paid, including all taxes (TTC).  \"tiers\": The name of the third party or vendor.  \"ht\": The amount before taxes (HT). \"dateDocument\": The date the document. \"sousChapitre\": always 09 - FACTURES. \"engagement\": Describes the specific commitment or purpose associated with the invoice. \"projet\": The name or description of the project related to the invoice. \"typeFacture\": Indicates the type of the facture (facture or estimation de travaux).'),\n",
        "            ChatMessage(role=\"user\", content=f\"Here are the document details: \\n{document_details}, create a JSON output\")\n",
        "        ]\n",
        "\n",
        "        chat_response = client.chat(model=model, response_format={\"type\": \"json_object\", \"schema\": Result.schema_json()}, messages=prompt)\n",
        "        llm_output = chat_response.choices[0].message.content\n",
        "        invoice_data[\"LLM_output\"] = llm_output\n",
        "        results.append(invoice_data)\n",
        "\n",
        "    with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = [\n",
        "           \"file_name\", \"LLM_output\", \"sentence\"\n",
        "        ]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for item in results:\n",
        "            writer.writerow(item)\n",
        "\n",
        "process_json_files(directory_path, output_file_path)"
      ],
      "metadata": {
        "id": "koQ_OL3Die50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "YRF7IwCv9VDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction de \"Pages\", nettoyage de la données et envoie dans OpenAI API (le modèle varie selon le nombre de tokens estimé)\n",
        "\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import glob\n",
        "import json\n",
        "import openai\n",
        "import chardet\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from pydantic import BaseModel\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/Complet'\n",
        "output_file_path = '/content/json_final_output_openai.csv'\n",
        "\n",
        "class Result(BaseModel):\n",
        "    vendorEmail: str\n",
        "    uo_2: str\n",
        "    invoiceNumber: str\n",
        "    vendorCode: str\n",
        "    commitmentCode: str\n",
        "    title: str\n",
        "    dueDate: str\n",
        "    documentType: str\n",
        "    vendorSiret: str\n",
        "    projectCode: str\n",
        "    ttc: str\n",
        "    tiers: str\n",
        "    ht: str\n",
        "    dateDocument: str\n",
        "    subChapter: str\n",
        "    commitment: str\n",
        "    project: str\n",
        "    invoiceType: str\n",
        "\n",
        "def estimate_token_count(text):\n",
        "    \"\"\"Estimate the number of tokens based on the text length.\n",
        "    Rough estimation assuming an average token length, including spaces.\"\"\"\n",
        "    return len(text) / 5\n",
        "\n",
        "def extract_data_json(json_file_path):\n",
        "    \"\"\"Extract and process data from a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(json_file_path, 'rb') as file:\n",
        "            raw_data = file.read()\n",
        "            if not raw_data:\n",
        "                print(f\"Warning: The file {json_file_path} is empty.\")\n",
        "                return None\n",
        "            encoding = chardet.detect(raw_data)['encoding'] or 'utf-8'\n",
        "            json_data = json.loads(raw_data.decode(encoding))\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from the file {json_file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    pages_data = json_data.get('pages', [])\n",
        "    sentences = []\n",
        "\n",
        "    for page in pages_data:\n",
        "        if page.get('$type') == 'PageContent':\n",
        "            for text_zone in page.get('Items', []):\n",
        "                if text_zone.get('$type') == 'TextZone':\n",
        "                    for line in text_zone.get('Ln', []):\n",
        "                        for item in line.get('Items', []):\n",
        "                            if item.get('$type') == 'Word':\n",
        "                                sentences.append(item.get('Value', ''))\n",
        "\n",
        "    sentence = ' '.join(sentences)\n",
        "    file_name = os.path.basename(json_file_path)\n",
        "    return {'sentence': sentence, 'file_name': file_name}\n",
        "\n",
        "def process_json_files(directory_path, output_file_path):\n",
        "    json_files = glob.glob(f\"{directory_path}/*.json\")\n",
        "    results = []\n",
        "    print(f\"Processing {len(json_files)} files...\")\n",
        "\n",
        "    for file_path in tqdm(json_files, desc=\"Progress\"):\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "        invoice_data = extract_data_json(file_path)\n",
        "        if invoice_data is None:\n",
        "            continue\n",
        "\n",
        "        sentence = invoice_data.get('sentence', '')\n",
        "        token_count = estimate_token_count(sentence)\n",
        "        if token_count > 32000:\n",
        "            max_length = 32000 * 5\n",
        "            invoice_data['sentence'] = sentence[:max_length]\n",
        "\n",
        "        document_details = invoice_data\n",
        "\n",
        "        token_count = estimate_token_count(document_details)\n",
        "        print(f\"Estimated token count for {file_path}: {token_count}\")\n",
        "\n",
        "        model = 'gpt-4-0125-preview' if token_count > 15500 else 'gpt-3.5-turbo-0125'\n",
        "\n",
        "        if token_count > 31000:\n",
        "            print(f\"{file_path} skipped due to token limit\")\n",
        "            continue\n",
        "\n",
        "        prompt = [\n",
        "            ChatMessage(role=\"system\", content='Create a JSON output with the following keys and their respective keys.  If the key is not present, the field is filled with an empty string or appears as NaN (Not a Number) in the dataset : vendor Email: Represents the email address of the vendor. uo_2: Denotes a specific organizational unit or department within a company, indicated by the key \"uo_2\". \"numeroPiece\": Contains the invoice number. \"codeTiers\": Corresponds to a unique code assigned to the vendor. \"codeEngagement\": Refers to a specific commitment or contract code associated with the invoice. \"title\": The title or name of the document, Title listed on the invoice, which usually describes the service or product sold. \"dueDate\": Indicates the due date of the invoice. \"typeDocument\": Specifies the type of document based on a pre-defined set of categories (09.01 - Factures / 09.04 - Factures développement (avant promesse) / 09.07 - Factures marketing / 09.08 - Factures travaux et prorata / 09.21 - Honoraires juridiques / 09.22 - Honoraires prescripteurs / 09.31 - Situations travaux MOE BPCC / 09.32 - Situations travaux MOE externe. »). \"tiersSiret\": A French SIRET number unique to each French company.  \"codeProjet\": Represents a unique code for the project associated with the invoice. \"ttc\": The total amount to be paid, including all taxes (TTC).  \"tiers\": The name of the third party or vendor.  \"ht\": The amount before taxes (HT). \"dateDocument\": The date the document. \"sousChapitre\": always 09 - FACTURES. \"engagement\": Describes the specific commitment or purpose associated with the invoice. \"projet\": The name or description of the project related to the invoice. \"typeFacture\": Indicates the type of the facture (facture or estimation de travaux).'),\n",
        "            ChatMessage(role=\"user\", content=f\"Here are the document details: \\n{document_details}, create a JSON output\")\n",
        "        ]\n",
        "\n",
        "        completion = client.chat.completions.create(model=model, response_format={ \"type\": \"json_object\" }, messages=prompt)\n",
        "        llm_output = completion.choices[0].message.content\n",
        "        invoice_data[\"LLM_output\"] = llm_output\n",
        "        results.append(invoice_data)\n",
        "\n",
        "    with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = [\n",
        "            \"sentence\", \"file_name\", \"LLM_output\"\n",
        "        ]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for item in results:\n",
        "            writer.writerow(item)\n",
        "\n",
        "process_json_files(directory_path, output_file_path)\n"
      ],
      "metadata": {
        "id": "NDOBXqz24aXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}